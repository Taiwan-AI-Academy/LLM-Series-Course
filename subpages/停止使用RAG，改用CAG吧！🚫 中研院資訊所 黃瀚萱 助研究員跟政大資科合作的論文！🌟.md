# 停止使用RAG，改用CAG吧！🚫 中研院資訊所 黃瀚萱 助研究員跟政大資科合作的論文！🌟

![472480686_930204522423194_4266104266384657792_n.jpg](../assets/%E5%81%9C%E6%AD%A2%E4%BD%BF%E7%94%A8RAG%EF%BC%8C%E6%94%B9%E7%94%A8CAG%E5%90%A7%EF%BC%81%F0%9F%9A%AB%20%E4%B8%AD%E7%A0%94%E9%99%A2%E8%B3%87%E8%A8%8A%E6%89%80%20%E9%BB%83%E7%80%9A%E8%90%B1%20%E5%8A%A9%E7%A0%94%E7%A9%B6%E5%93%A1%E8%B7%9F%E6%94%BF%E5%A4%A7%E8%B3%87%E7%A7%91%E5%90%88%E4%BD%9C%E7%9A%84%E8%AB%96%E6%96%87%EF%BC%81%F0%9F%8C%9F/472480686_930204522423194_4266104266384657792_n.jpg)

傳統RAG存在著一些問題：檢索延遲、文件選擇錯誤，以及系統複雜。研究團隊因而提出Cache增強生成(CAG)方法。⚠️

🔍 該方法出奇的簡單：

1. 知識預加載：系統預先將所有相關文件轉換爲KV緩存。
2. 推理階段：當使用者提出問題時，系統直接使用預加載的緩存生成答案。
3. 緩存重置：透過截斷，系統可以快速重置緩存。

📊 研究團隊在SQuAD和HotPotQA進行了詳細的實驗：

- 性能提升：在大多數測試場景中，CAG方法的BERT-Score評分都優於傳統的RAG系統。
- 時間效率：由於無需即時檢索，回答生成時間大幅縮短，尤其在長文本時，優勢更明顯。
- 架構簡化：移除了檢索器和生成器的整合需求，降低了系統維護的複雜度。

隨著大語言模型的上下文處理能力不斷提升，CAG方法不僅適用於知識庫規模可控的和需要即時回應的問答系統。🚀

不過，對於開放問答或知識庫經常更新的場景，傳統RAG方法可能仍是更好的選擇。⚖️

論文來源：
[https://arxiv.org/abs/2412.15605](https://arxiv.org/abs/2412.15605)